{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the source code of the Iteration 4 for Info722 Assessment\n",
    "\n",
    "All the code is coding on the jupyter notebook on AWS EC2 Instance services\n",
    "\n",
    "Instance ID i-09e9cee8d00d748c2\n",
    "Public IPv4 address 34.202.158.7 | open address \n",
    "Instance state Running\n",
    "Public IPv4 DNS ec2-34-202-158-7.compute-1.amazonaws.com | open address "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 Data Preparing\n",
    "\n",
    "This part is coding and testing twice, with the data file in the data folder located on AWS EC2 Instance, and the other is directly read the csv files via URL from the NZTA website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is initial the pyspark envrionment\n",
    "\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "\n",
    "# Import pyspark modules\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()\n",
    "\n",
    "# import the matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the pyspark function\n",
    "import pyspark.sql.functions as fn\n",
    "\n",
    "# import the date time functions \n",
    "from pyspark.sql.functions import dayofmonth,month,hour,year,format_number\n",
    "\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data from the csv files \n",
    "All the csv files are unloaded into ../data folder\n",
    "\n",
    "#### Get the csv files directly from the NZTA website\n",
    "This part will not include in the final run, because the performance issue, need wait long time for the data transfering between AWS data centre and NZTA webside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial the csv files location and file names\n",
    "# This is just teting run to verify performance and stability \n",
    "\n",
    "# FileVehicleYear2015 = \"https://nztaopendata.blob.core.windows.net/motorvehicleregister/VehicleYear-2015.csv\"\n",
    "# FileVehicleYear2016 = \"https://nztaopendata.blob.core.windows.net/motorvehicleregister/VehicleYear-2016.csv\"\n",
    "# FileVehicleYear2017 = \"https://nztaopendata.blob.core.windows.net/motorvehicleregister/VehicleYear-2017.csv\"\n",
    "# FileVehicleYear2018 = \"https://nztaopendata.blob.core.windows.net/motorvehicleregister/VehicleYear-2018.csv\"\n",
    "# FileVehicleYear2019 = \"https://nztaopendata.blob.core.windows.net/motorvehicleregister/VehicleYear-2019.csv\"\n",
    "# FileVehicleYear2020 = \"https://nztaopendata.blob.core.windows.net/motorvehicleregister/VehicleYear-2020.csv\"\n",
    "# \n",
    "# # Import the public libs for the data frame and read data from csv files\n",
    "# \n",
    "# from pyspark import SparkFiles\n",
    "# from pyspark.sql.types import StructType,StructField, StringType, IntegerType \n",
    "# from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "# \n",
    "# #Get the file content via the URLs\n",
    "# spark.sparkContext.addFile(FileVehicleYear2015)\n",
    "# VehicleYear2015 = spark.read.option(\"header\",True).csv(SparkFiles.get(\"VehicleYear-2015.csv\"))\n",
    "# \n",
    "# spark.sparkContext.addFile(FileVehicleYear2016)\n",
    "# VehicleYear2016 = spark.read.option(\"header\",True).csv(SparkFiles.get(\"VehicleYear-2016.csv\"))\n",
    "# \n",
    "# spark.sparkContext.addFile(FileVehicleYear2017)\n",
    "# VehicleYear2017 = spark.read.option(\"header\",True).csv(SparkFiles.get(\"VehicleYear-2017.csv\"))\n",
    "# \n",
    "# spark.sparkContext.addFile(FileVehicleYear2018)\n",
    "# VehicleYear2018 = spark.read.option(\"header\",True).csv(SparkFiles.get(\"VehicleYear-2018.csv\"))\n",
    "# \n",
    "# spark.sparkContext.addFile(FileVehicleYear2019)\n",
    "# VehicleYear2019 = spark.read.option(\"header\",True).csv(SparkFiles.get(\"VehicleYear-2019.csv\"))\n",
    "\n",
    "# Verify the performance \n",
    "# print(VehicleYear2015.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the csv files directly from the local drivers\n",
    "Upload the data files into the ./data folder, and pyspark will import the data from local drivers, and this will much faster than get the data via internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ALTERNATIVE_MOTIVE_POWER: string (nullable = true)\n",
      " |-- BASIC_COLOUR: string (nullable = true)\n",
      " |-- BODY_TYPE: string (nullable = true)\n",
      " |-- CC_RATING: integer (nullable = true)\n",
      " |-- CHASSIS7: string (nullable = true)\n",
      " |-- CLASS: string (nullable = true)\n",
      " |-- ENGINE_NUMBER: string (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_YEAR: integer (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_MONTH: integer (nullable = true)\n",
      " |-- GROSS_VEHICLE_MASS: decimal(6,0) (nullable = true)\n",
      " |-- HEIGHT: integer (nullable = true)\n",
      " |-- IMPORT_STATUS: string (nullable = true)\n",
      " |-- INDUSTRY_CLASS: string (nullable = true)\n",
      " |-- INDUSTRY_MODEL_CODE: string (nullable = true)\n",
      " |-- MAKE: string (nullable = true)\n",
      " |-- MODEL: string (nullable = true)\n",
      " |-- MOTIVE_POWER: string (nullable = true)\n",
      " |-- MVMA_MODEL_CODE: string (nullable = true)\n",
      " |-- NUMBER_OF_AXLES: integer (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: integer (nullable = true)\n",
      " |-- NZ_ASSEMBLED: string (nullable = true)\n",
      " |-- ORIGINAL_COUNTRY: string (nullable = true)\n",
      " |-- POWER_RATING: integer (nullable = true)\n",
      " |-- PREVIOUS_COUNTRY: string (nullable = true)\n",
      " |-- ROAD_TRANSPORT_CODE: string (nullable = true)\n",
      " |-- SUBMODEL: string (nullable = true)\n",
      " |-- TLA: string (nullable = true)\n",
      " |-- TRANSMISSION_TYPE: string (nullable = true)\n",
      " |-- VDAM_WEIGHT: integer (nullable = true)\n",
      " |-- VEHICLE_TYPE: string (nullable = true)\n",
      " |-- VEHICLE_USAGE: string (nullable = true)\n",
      " |-- VEHICLE_YEAR: integer (nullable = true)\n",
      " |-- VIN11: string (nullable = true)\n",
      " |-- WIDTH: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ALTERNATIVE_MOTIVE_POWER: string (nullable = true)\n",
      " |-- BASIC_COLOUR: string (nullable = true)\n",
      " |-- BODY_TYPE: string (nullable = true)\n",
      " |-- CC_RATING: integer (nullable = true)\n",
      " |-- CHASSIS7: string (nullable = true)\n",
      " |-- CLASS: string (nullable = true)\n",
      " |-- ENGINE_NUMBER: string (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_YEAR: integer (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_MONTH: integer (nullable = true)\n",
      " |-- GROSS_VEHICLE_MASS: decimal(10,0) (nullable = true)\n",
      " |-- HEIGHT: integer (nullable = true)\n",
      " |-- IMPORT_STATUS: string (nullable = true)\n",
      " |-- INDUSTRY_CLASS: string (nullable = true)\n",
      " |-- INDUSTRY_MODEL_CODE: string (nullable = true)\n",
      " |-- MAKE: string (nullable = true)\n",
      " |-- MODEL: string (nullable = true)\n",
      " |-- MOTIVE_POWER: string (nullable = true)\n",
      " |-- MVMA_MODEL_CODE: string (nullable = true)\n",
      " |-- NUMBER_OF_AXLES: integer (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: integer (nullable = true)\n",
      " |-- NZ_ASSEMBLED: string (nullable = true)\n",
      " |-- ORIGINAL_COUNTRY: string (nullable = true)\n",
      " |-- POWER_RATING: integer (nullable = true)\n",
      " |-- PREVIOUS_COUNTRY: string (nullable = true)\n",
      " |-- ROAD_TRANSPORT_CODE: string (nullable = true)\n",
      " |-- SUBMODEL: string (nullable = true)\n",
      " |-- TLA: string (nullable = true)\n",
      " |-- TRANSMISSION_TYPE: string (nullable = true)\n",
      " |-- VDAM_WEIGHT: integer (nullable = true)\n",
      " |-- VEHICLE_TYPE: string (nullable = true)\n",
      " |-- VEHICLE_USAGE: string (nullable = true)\n",
      " |-- VEHICLE_YEAR: integer (nullable = true)\n",
      " |-- VIN11: string (nullable = true)\n",
      " |-- WIDTH: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ALTERNATIVE_MOTIVE_POWER: string (nullable = true)\n",
      " |-- BASIC_COLOUR: string (nullable = true)\n",
      " |-- BODY_TYPE: string (nullable = true)\n",
      " |-- CC_RATING: integer (nullable = true)\n",
      " |-- CHASSIS7: string (nullable = true)\n",
      " |-- CLASS: string (nullable = true)\n",
      " |-- ENGINE_NUMBER: string (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_YEAR: integer (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_MONTH: integer (nullable = true)\n",
      " |-- GROSS_VEHICLE_MASS: decimal(10,0) (nullable = true)\n",
      " |-- HEIGHT: integer (nullable = true)\n",
      " |-- IMPORT_STATUS: string (nullable = true)\n",
      " |-- INDUSTRY_CLASS: string (nullable = true)\n",
      " |-- INDUSTRY_MODEL_CODE: string (nullable = true)\n",
      " |-- MAKE: string (nullable = true)\n",
      " |-- MODEL: string (nullable = true)\n",
      " |-- MOTIVE_POWER: string (nullable = true)\n",
      " |-- MVMA_MODEL_CODE: string (nullable = true)\n",
      " |-- NUMBER_OF_AXLES: integer (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: integer (nullable = true)\n",
      " |-- NZ_ASSEMBLED: string (nullable = true)\n",
      " |-- ORIGINAL_COUNTRY: string (nullable = true)\n",
      " |-- POWER_RATING: integer (nullable = true)\n",
      " |-- PREVIOUS_COUNTRY: string (nullable = true)\n",
      " |-- ROAD_TRANSPORT_CODE: string (nullable = true)\n",
      " |-- SUBMODEL: string (nullable = true)\n",
      " |-- TLA: string (nullable = true)\n",
      " |-- TRANSMISSION_TYPE: string (nullable = true)\n",
      " |-- VDAM_WEIGHT: integer (nullable = true)\n",
      " |-- VEHICLE_TYPE: string (nullable = true)\n",
      " |-- VEHICLE_USAGE: string (nullable = true)\n",
      " |-- VEHICLE_YEAR: integer (nullable = true)\n",
      " |-- VIN11: string (nullable = true)\n",
      " |-- WIDTH: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ALTERNATIVE_MOTIVE_POWER: string (nullable = true)\n",
      " |-- BASIC_COLOUR: string (nullable = true)\n",
      " |-- BODY_TYPE: string (nullable = true)\n",
      " |-- CC_RATING: integer (nullable = true)\n",
      " |-- CHASSIS7: string (nullable = true)\n",
      " |-- CLASS: string (nullable = true)\n",
      " |-- ENGINE_NUMBER: string (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_YEAR: integer (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_MONTH: integer (nullable = true)\n",
      " |-- GROSS_VEHICLE_MASS: decimal(6,0) (nullable = true)\n",
      " |-- HEIGHT: integer (nullable = true)\n",
      " |-- IMPORT_STATUS: string (nullable = true)\n",
      " |-- INDUSTRY_CLASS: string (nullable = true)\n",
      " |-- INDUSTRY_MODEL_CODE: string (nullable = true)\n",
      " |-- MAKE: string (nullable = true)\n",
      " |-- MODEL: string (nullable = true)\n",
      " |-- MOTIVE_POWER: string (nullable = true)\n",
      " |-- MVMA_MODEL_CODE: string (nullable = true)\n",
      " |-- NUMBER_OF_AXLES: integer (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: integer (nullable = true)\n",
      " |-- NZ_ASSEMBLED: string (nullable = true)\n",
      " |-- ORIGINAL_COUNTRY: string (nullable = true)\n",
      " |-- POWER_RATING: integer (nullable = true)\n",
      " |-- PREVIOUS_COUNTRY: string (nullable = true)\n",
      " |-- ROAD_TRANSPORT_CODE: string (nullable = true)\n",
      " |-- SUBMODEL: string (nullable = true)\n",
      " |-- TLA: string (nullable = true)\n",
      " |-- TRANSMISSION_TYPE: string (nullable = true)\n",
      " |-- VDAM_WEIGHT: integer (nullable = true)\n",
      " |-- VEHICLE_TYPE: string (nullable = true)\n",
      " |-- VEHICLE_USAGE: string (nullable = true)\n",
      " |-- VEHICLE_YEAR: integer (nullable = true)\n",
      " |-- VIN11: string (nullable = true)\n",
      " |-- WIDTH: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ALTERNATIVE_MOTIVE_POWER: string (nullable = true)\n",
      " |-- BASIC_COLOUR: string (nullable = true)\n",
      " |-- BODY_TYPE: string (nullable = true)\n",
      " |-- CC_RATING: integer (nullable = true)\n",
      " |-- CHASSIS7: string (nullable = true)\n",
      " |-- CLASS: string (nullable = true)\n",
      " |-- ENGINE_NUMBER: string (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_YEAR: integer (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_MONTH: integer (nullable = true)\n",
      " |-- GROSS_VEHICLE_MASS: decimal(6,0) (nullable = true)\n",
      " |-- HEIGHT: integer (nullable = true)\n",
      " |-- IMPORT_STATUS: string (nullable = true)\n",
      " |-- INDUSTRY_CLASS: string (nullable = true)\n",
      " |-- INDUSTRY_MODEL_CODE: string (nullable = true)\n",
      " |-- MAKE: string (nullable = true)\n",
      " |-- MODEL: string (nullable = true)\n",
      " |-- MOTIVE_POWER: string (nullable = true)\n",
      " |-- MVMA_MODEL_CODE: string (nullable = true)\n",
      " |-- NUMBER_OF_AXLES: integer (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: integer (nullable = true)\n",
      " |-- NZ_ASSEMBLED: string (nullable = true)\n",
      " |-- ORIGINAL_COUNTRY: string (nullable = true)\n",
      " |-- POWER_RATING: integer (nullable = true)\n",
      " |-- PREVIOUS_COUNTRY: string (nullable = true)\n",
      " |-- ROAD_TRANSPORT_CODE: string (nullable = true)\n",
      " |-- SUBMODEL: string (nullable = true)\n",
      " |-- TLA: string (nullable = true)\n",
      " |-- TRANSMISSION_TYPE: string (nullable = true)\n",
      " |-- VDAM_WEIGHT: integer (nullable = true)\n",
      " |-- VEHICLE_TYPE: string (nullable = true)\n",
      " |-- VEHICLE_USAGE: string (nullable = true)\n",
      " |-- VEHICLE_YEAR: integer (nullable = true)\n",
      " |-- VIN11: string (nullable = true)\n",
      " |-- WIDTH: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the csv files from the local drivers \n",
    "# Initial the csv files location \n",
    "\n",
    "# Get the file path of the data files, this is the relavent path \n",
    "FileVehiclePath = \"./data/\"\n",
    "\n",
    "# 2.1 Collect initial data\n",
    "# Get the five vehciles data files which download from NZTA website\n",
    "FileVehicleYear2015 = FileVehiclePath + \"VehicleYear-2015.csv\"\n",
    "FileVehicleYear2016 = FileVehiclePath + \"VehicleYear-2016.csv\"\n",
    "FileVehicleYear2017 = FileVehiclePath + \"VehicleYear-2017.csv\"\n",
    "FileVehicleYear2018 = FileVehiclePath + \"VehicleYear-2018.csv\"\n",
    "FileVehicleYear2019 = FileVehiclePath + \"VehicleYear-2019.csv\"\n",
    "\n",
    "# Read in the CSV data.\n",
    "VehicleYear2015 = spark.read.csv(FileVehicleYear2015,inferSchema=True,header=True)\n",
    "VehicleYear2016 = spark.read.csv(FileVehicleYear2016,inferSchema=True,header=True)\n",
    "VehicleYear2017 = spark.read.csv(FileVehicleYear2017,inferSchema=True,header=True)\n",
    "VehicleYear2018 = spark.read.csv(FileVehicleYear2018,inferSchema=True,header=True)\n",
    "VehicleYear2019 = spark.read.csv(FileVehicleYear2019,inferSchema=True,header=True)\n",
    "\n",
    "# Check if the data is loaded, and file schemas are recognized\n",
    "VehicleYear2015.printSchema()\n",
    "VehicleYear2016.printSchema()\n",
    "VehicleYear2017.printSchema()\n",
    "VehicleYear2018.printSchema()\n",
    "VehicleYear2019.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the 5 years datasets into one, all the data analysis will based on the merge dataset\n",
    "To imporve the performance issue, and just in case if the data files provide by NZTA contains the duplication, will use the reduce function to remove the duplication via the VIN11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data frame moduels and will use reduce to union/merger all dataset together\n",
    "from functools import reduce \n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "df_VehicleYear2015 = VehicleYear2015\n",
    "df_VehicleYear2016 = VehicleYear2016\n",
    "df_VehicleYear2017 = VehicleYear2017\n",
    "df_VehicleYear2018 = VehicleYear2018\n",
    "df_VehicleYear2019 = VehicleYear2019\n",
    "\n",
    "df_VehicleMerge = [df_VehicleYear2015,df_VehicleYear2016,df_VehicleYear2017,df_VehicleYear2018,df_VehicleYear2019]\n",
    "df_VehicleAll = reduce(DataFrame.unionAll,df_VehicleMerge)\n",
    "\n",
    "#df_VehicleAll.show()\n",
    "#Get the statistics of the final merge dataset size \n",
    "df_VehicleAll_rowcount = df_VehicleAll.count()\n",
    "df_VehicleAll_colnumber = len(df_VehicleAll.dtypes)\n",
    "\n",
    "#Get the statistics of the 2015 dataset size\n",
    "df_VehicleYear2015_rowcount = df_VehicleYear2015.count()\n",
    "df_VehicleYear2015_colnumber = len(df_VehicleYear2015.dtypes)\n",
    "\n",
    "#Get the statistics of the 2016 dataset size\n",
    "df_VehicleYear2016_rowcount = df_VehicleYear2016.count()\n",
    "df_VehicleYear2016_colnumber = len(df_VehicleYear2016.dtypes)\n",
    "\n",
    "#Get the statistics of the 2017 dataset size\n",
    "df_VehicleYear2017_rowcount = df_VehicleYear2017.count()\n",
    "df_VehicleYear2017_colnumber = len(df_VehicleYear2017.dtypes)\n",
    "\n",
    "#Get the statistics of the 2018 dataset size\n",
    "df_VehicleYear2018_rowcount = df_VehicleYear2018.count()\n",
    "df_VehicleYear2018_colnumber = len(df_VehicleYear2018.dtypes)\n",
    "\n",
    "#Get the statistics of the 2019 dataset size\n",
    "df_VehicleYear2019_rowcount = df_VehicleYear2019.count()\n",
    "df_VehicleYear2019_colnumber = len(df_VehicleYear2019.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count from 2015 - 2019:  1017971\n",
      "Total count for 2015:  186749\n",
      "Total count for 2016:  198389\n",
      "Total count for 2017:  212335\n",
      "Total count for 2018:  214225\n",
      "Total count for 2019:  206273\n",
      "+--------------------------------+--------------------+-----------------+-----------------+------------------+--------------------+---------------------+----------------------------------+-----------------------------------+--------------------------+--------------+---------------------+----------------------+---------------------------+------------+--------------------+--------------------+-----------------------+-----------------------+-----------------------+--------------------+------------------------+--------------------+------------------------+---------------------------+------------------+-----------+-------------------------+-------------------+--------------------+---------------------+--------------------+-------------------+-------------+\n",
      "|ALTERNATIVE_MOTIVE_POWER_missing|BASIC_COLOUR_missing|BODY_TYPE_missing|CC_RATING_missing|  CHASSIS7_missing|       CLASS_missing|ENGINE_NUMBER_missing|FIRST_NZ_REGISTRATION_YEAR_missing|FIRST_NZ_REGISTRATION_MONTH_missing|GROSS_VEHICLE_MASS_missing|HEIGHT_missing|IMPORT_STATUS_missing|INDUSTRY_CLASS_missing|INDUSTRY_MODEL_CODE_missing|MAKE_missing|       MODEL_missing|MOTIVE_POWER_missing|MVMA_MODEL_CODE_missing|NUMBER_OF_AXLES_missing|NUMBER_OF_SEATS_missing|NZ_ASSEMBLED_missing|ORIGINAL_COUNTRY_missing|POWER_RATING_missing|PREVIOUS_COUNTRY_missing|ROAD_TRANSPORT_CODE_missing|  SUBMODEL_missing|TLA_missing|TRANSMISSION_TYPE_missing|VDAM_WEIGHT_missing|VEHICLE_TYPE_missing|VEHICLE_USAGE_missing|VEHICLE_YEAR_missing|      VIN11_missing|WIDTH_missing|\n",
      "+--------------------------------+--------------------+-----------------+-----------------+------------------+--------------------+---------------------+----------------------------------+-----------------------------------+--------------------------+--------------+---------------------+----------------------+---------------------------+------------+--------------------+--------------------+-----------------------+-----------------------+-----------------------+--------------------+------------------------+--------------------+------------------------+---------------------------+------------------+-----------+-------------------------+-------------------+--------------------+---------------------+--------------------+-------------------+-------------+\n",
      "|              0.9350020776623302|                 0.0|              0.0|              0.0|0.8871421680971265|2.554100264152703...|  0.17994618707212684|              1.473519383166088...|               1.473519383166088...|                       0.0|           0.0|                  0.0|                   0.0|         0.9670894357501343|         0.0|9.823462554514606E-7| 0.17355700702672272|    0.24936270286678108|                    0.0|                    0.0|                 0.0|                     0.0|                 0.0|                     0.0|         0.9737507257082962|0.2146416744681332|        1.0|       0.2855189391446318|                0.0|                 0.0|                  0.0|                 0.0|0.18644440755188507|          0.0|\n",
      "+--------------------------------+--------------------+-----------------+-----------------+------------------+--------------------+---------------------+----------------------------------+-----------------------------------+--------------------------+--------------+---------------------+----------------------+---------------------------+------------+--------------------+--------------------+-----------------------+-----------------------+-----------------------+--------------------+------------------------+--------------------+------------------------+---------------------------+------------------+-----------+-------------------------+-------------------+--------------------+---------------------+--------------------+-------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(ALTERNATIVE_MOTIVE_POWER=None, BASIC_COLOUR='WHITE', BODY_TYPE='DOMESTIC TRAILER', CC_RATING=0, CHASSIS7=None, CLASS='TB', ENGINE_NUMBER=None, FIRST_NZ_REGISTRATION_YEAR=2018, FIRST_NZ_REGISTRATION_MONTH=8, GROSS_VEHICLE_MASS=Decimal('2500'), HEIGHT=0, IMPORT_STATUS='SCRATCH', INDUSTRY_CLASS='UNKNOWN', INDUSTRY_MODEL_CODE=None, MAKE='HOMEBUILT', MODEL='TRAILER', MOTIVE_POWER=None, MVMA_MODEL_CODE=None, NUMBER_OF_AXLES=1, NUMBER_OF_SEATS=0, NZ_ASSEMBLED='NZ ASSEMBLED/BUILT', ORIGINAL_COUNTRY='NEW ZEALAND', POWER_RATING=0, PREVIOUS_COUNTRY='NONE', ROAD_TRANSPORT_CODE=None, SUBMODEL=None, TLA=None, TRANSMISSION_TYPE=None, VDAM_WEIGHT=0, VEHICLE_TYPE='TRAILER/CARAVAN', VEHICLE_USAGE='OTHER GOODS', VEHICLE_YEAR=2018, VIN11=None, WIDTH=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the sum of data row count for each year is the same as total \n",
    "\n",
    "print(\"Total count from 2015 - 2019: \",df_VehicleAll_rowcount)\n",
    "print(\"Total count for 2015: \",df_VehicleYear2015_rowcount)\n",
    "print(\"Total count for 2016: \",df_VehicleYear2016_rowcount)\n",
    "print(\"Total count for 2017: \",df_VehicleYear2017_rowcount)\n",
    "print(\"Total count for 2018: \",df_VehicleYear2018_rowcount)\n",
    "print(\"Total count for 2019: \",df_VehicleYear2019_rowcount)\n",
    "#\n",
    "\n",
    "# df_VehicleYear2018.head(5)\n",
    "\n",
    "# Check the data missing, and for the MOTIVE_POWER need to be fixed the missing records before process\n",
    "df_VehicleAll.agg(*[(1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing') for c in df_VehicleAll.columns]).show()\n",
    "\n",
    "df_VehicleYear2018.where(\"MOTIVE_POWER is null\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count before clean up:  1017971\n",
      "Row count after clean up:  841295\n"
     ]
    }
   ],
   "source": [
    "# Filter the non power vehicles\n",
    "# Processing the data Quality\n",
    "# Filter outer the missing value records on MOTIVE_POWER, all the \"TRAILER\" type vehciles, which \n",
    "# do not contain the engins \n",
    "# Row count before clean up\n",
    "\n",
    "df_VehicleAll\n",
    "#\n",
    "print(\"Row count before clean up: \" ,df_VehicleAll.count())\n",
    "df_VehicleAll = df_VehicleAll.filter(\"MAKE <> \\\"TRAILER\\\"\" and \"MOTIVE_POWER <> \\\"\\\"\" \n",
    "                            and \"IMPORT_STATUS <> \\\"SCRATCH\\\"\" \n",
    "                            and \"FIRST_NZ_REGISTRATION_YEAR < \\\"2020\\\"\"\n",
    "                            and \"VEHICLE_TYPE not LIKE \\\"%TRAILER%\\\" \")\n",
    "\n",
    "# Row count after clean up\n",
    "print(\"Row count after clean up: \" ,df_VehicleAll.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ALTERNATIVE_MOTIVE_POWER=None, BASIC_COLOUR='WHITE', BODY_TYPE='OTHER TRUCK', CC_RATING=4009, CHASSIS7='JHHNCT2', CLASS='NB', ENGINE_NUMBER='NO4C-UT15093', FIRST_NZ_REGISTRATION_YEAR=2015, FIRST_NZ_REGISTRATION_MONTH=3, GROSS_VEHICLE_MASS=Decimal('8500'), HEIGHT=2560, IMPORT_STATUS='NEW', INDUSTRY_CLASS='CONSTRUCTING', INDUSTRY_MODEL_CODE=None, MAKE='HINO', MODEL='300', MOTIVE_POWER='DIESEL', MVMA_MODEL_CODE=None, NUMBER_OF_AXLES=2, NUMBER_OF_SEATS=3, NZ_ASSEMBLED='IMPORTED BUILT-UP', ORIGINAL_COUNTRY='JAPAN', POWER_RATING=0, PREVIOUS_COUNTRY='NONE', ROAD_TRANSPORT_CODE=None, SUBMODEL='XZU730R-QKFTTQ3', TLA=None, TRANSMISSION_TYPE=None, VDAM_WEIGHT=14200, VEHICLE_TYPE='GOODS VAN/TRUCK/UTILITY', VEHICLE_USAGE='TRANSPORT LICENSED GOODS', VEHICLE_YEAR=2015, VIN11='JHHNCT2H70K', WIDTH=2220)\n",
      "DataFrame[summary: string, ALTERNATIVE_MOTIVE_POWER: string, BASIC_COLOUR: string, BODY_TYPE: string, CC_RATING: string, CHASSIS7: string, CLASS: string, ENGINE_NUMBER: string, FIRST_NZ_REGISTRATION_YEAR: string, FIRST_NZ_REGISTRATION_MONTH: string, GROSS_VEHICLE_MASS: string, HEIGHT: string, IMPORT_STATUS: string, INDUSTRY_CLASS: string, INDUSTRY_MODEL_CODE: string, MAKE: string, MODEL: string, MOTIVE_POWER: string, MVMA_MODEL_CODE: string, NUMBER_OF_AXLES: string, NUMBER_OF_SEATS: string, NZ_ASSEMBLED: string, ORIGINAL_COUNTRY: string, POWER_RATING: string, PREVIOUS_COUNTRY: string, ROAD_TRANSPORT_CODE: string, SUBMODEL: string, TLA: string, TRANSMISSION_TYPE: string, VDAM_WEIGHT: string, VEHICLE_TYPE: string, VEHICLE_USAGE: string, VEHICLE_YEAR: string, VIN11: string, WIDTH: string]\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Describe the data\n",
    "print (df_VehicleAll.head())\n",
    "print (df_VehicleAll.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infosys 722 Python Assessment Iteration 4  Data Preparing\n",
    "Adding the Promotion column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ALTERNATIVE_MOTIVE_POWER=None, BASIC_COLOUR='RED', BODY_TYPE='HATCHBACK', CC_RATING=1, CHASSIS7=None, CLASS='MA', ENGINE_NUMBER='EM0003-7809930001', FIRST_NZ_REGISTRATION_YEAR=2018, FIRST_NZ_REGISTRATION_MONTH=3, GROSS_VEHICLE_MASS=Decimal('1060'), HEIGHT=0, IMPORT_STATUS='USED', INDUSTRY_CLASS='PRIVATE', INDUSTRY_MODEL_CODE='ZAA-451390', MAKE='SMART', MODEL='FORTWO', MOTIVE_POWER='ELECTRIC', MVMA_MODEL_CODE=None, NUMBER_OF_AXLES=2, NUMBER_OF_SEATS=2, NZ_ASSEMBLED='IMPORTED BUILT-UP', ORIGINAL_COUNTRY='GERMANY', POWER_RATING=0, PREVIOUS_COUNTRY='JAPAN', ROAD_TRANSPORT_CODE=None, SUBMODEL='ELECTRIC DRIVE', TLA=None, TRANSMISSION_TYPE=None, VDAM_WEIGHT=0, VEHICLE_TYPE='PASSENGER CAR/VAN', VEHICLE_USAGE='PRIVATE PASSENGER', VEHICLE_YEAR=2015, VIN11='WME4513902K', WIDTH=0, Promotion=1, EV_Flag=1, RunningCost=0.4477611940298508)\n"
     ]
    }
   ],
   "source": [
    "#Infosys 722 Python Assessment Iteration 4  Data Preparing\n",
    "#\n",
    "#4. Data Transformation\n",
    "#4.1    Data Reduce and resharp\n",
    "#This is reference in the reference section 8\n",
    "#Based on the Ministry of Trannsport of New Zealand website, there is govement promotion programme \n",
    "#which encourage consumers to choose electric vehicles. The key importance of the promotion is the \n",
    "#exemption of the Road user cost, from that website, officially announced that buying a electric \n",
    "#vehicles will save appromaxmately $600 per year per vehicles, in Using the derived stage to adding \n",
    "#the EV and from 2017, there is promotion column with integer type and value is 600\n",
    "#\n",
    "#\n",
    "# Adding the Promotion column \n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Adding the Promotion column \n",
    "# Conditions = [(VechileAll[\"MOTIVE_POWER\"] == 'ELECTRIC') & (VechileAll[\"FIRST_NZ_REGISTRATION_YEAR\"] > 2016) ]\n",
    "df_VehicleAll_New = df_VehicleAll.select(col(\"*\"),when((col(\"MOTIVE_POWER\") == \"ELECTRIC\") & (col(\"FIRST_NZ_REGISTRATION_YEAR\") > 2016) \\\n",
    "                                               ,1).otherwise(0).alias(\"Promotion\")   )\n",
    "#\n",
    "# Adding the EV_Flag column \n",
    "#Conditions = [(VechileAll[\"MOTIVE_POWER\"] == 'ELECTRIC')]\n",
    "df_VehicleAll_New = df_VehicleAll_New.select(col(\"*\"),when((col(\"MOTIVE_POWER\") == \"ELECTRIC\") \\\n",
    "                                               ,1).otherwise(0).alias(\"EV_Flag\")   )\n",
    "\n",
    "#This is reference in the reference section 9\n",
    "#The running cost, the source data is from the Gen Less government website, Figure NZ website, \n",
    "#to get the EV vehicles equvilalent price of petrol and the average price of petrol from 2015-2019, \n",
    "#to calculate the % of EV running cost against tranditional vehicles. \n",
    "df_VehicleAll_New = df_VehicleAll_New.select(col(\"*\") \\\n",
    "                                    ,when((col(\"EV_Flag\") == 1)&(col(\"FIRST_NZ_REGISTRATION_YEAR\") == 2015),0.9/1.83) \\\n",
    "                                    .when((col(\"EV_Flag\") == 1)&(col(\"FIRST_NZ_REGISTRATION_YEAR\") == 2016),0.9/1.73) \\\n",
    "                                    .when((col(\"EV_Flag\") == 1)&(col(\"FIRST_NZ_REGISTRATION_YEAR\") == 2017),0.9/1.88) \\\n",
    "                                    .when((col(\"EV_Flag\") == 1)&(col(\"FIRST_NZ_REGISTRATION_YEAR\") == 2018),0.9/2.01) \\\n",
    "                                    .when((col(\"EV_Flag\") == 1)&(col(\"FIRST_NZ_REGISTRATION_YEAR\") == 2019),0.9/1.93) \\\n",
    "                                    .otherwise(1).alias(\"RunningCost\"))\n",
    "\n",
    "# Testing the selection logic\n",
    "print (df_VehicleAll_New.filter(\"EV_Flag = 1\").head())\n",
    "\n",
    "df_VehicleAll_EV = df_VehicleAll_New.filter(\"EV_Flag = 1\")\n",
    "\n",
    "#print ('Count of rows: {0}'.format(df_VehicleAll_New.count()))\n",
    "#print ('Count of distinct rows: {0}'.format(df_VehicleAll_New.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows: 841295\n",
      "Count of distinct rows: 839381\n",
      "+-------+------------------+-------------------------------+--------------------------------+--------------------+--------------------+-----------------+-----------------+------------+-----------------+------------------+\n",
      "|EV_flag|    avg(CC_RATING)|avg(FIRST_NZ_REGISTRATION_YEAR)|avg(FIRST_NZ_REGISTRATION_MONTH)|avg(NUMBER_OF_AXLES)|avg(NUMBER_OF_SEATS)|avg(POWER_RATING)|avg(VEHICLE_YEAR)|avg(EV_flag)|   avg(Promotion)|  avg(RunningCost)|\n",
      "+-------+------------------+-------------------------------+--------------------------------+--------------------+--------------------+-----------------+-----------------+------------+-----------------+------------------+\n",
      "|      1|43.229678123295145|             2018.2575013638843|                7.02924168030551|    1.69012547735952|   4.589198036006547|55.65390070921986|2016.998363338789|         1.0|0.951227495908347|0.5139562154969843|\n",
      "+-------+------------------+-------------------------------+--------------------------------+--------------------+--------------------+-----------------+-----------------+------------+-----------------+------------------+\n",
      "\n",
      "839366\n",
      "+-------+------------+------------------+------------------+--------------+--------------------------+---------------------------+-------------+-------+------------+--------------------+------------------+-----------------+-----------------+----------------+------------------+--------------------+------------------+-----------+--------------------+--------------------+-------------------+\n",
      "|summary|BASIC_COLOUR|         BODY_TYPE|         CC_RATING| ENGINE_NUMBER|FIRST_NZ_REGISTRATION_YEAR|FIRST_NZ_REGISTRATION_MONTH|IMPORT_STATUS|   MAKE|       MODEL|        MOTIVE_POWER|   NUMBER_OF_AXLES|  NUMBER_OF_SEATS|     NZ_ASSEMBLED|ORIGINAL_COUNTRY|      POWER_RATING|        VEHICLE_TYPE|      VEHICLE_YEAR|      VIN11|             EV_flag|           Promotion|        RunningCost|\n",
      "+-------+------------+------------------+------------------+--------------+--------------------------+---------------------------+-------------+-------+------------+--------------------+------------------+-----------------+-----------------+----------------+------------------+--------------------+------------------+-----------+--------------------+--------------------+-------------------+\n",
      "|  count|      839366|            839366|            839366|        833171|                    839366|                     839366|       839366| 839366|      839366|              839366|            839366|           839366|           839366|          839366|            839366|              839366|            839366|     818925|              839366|              839366|             839366|\n",
      "|   mean|        null|              null|2437.9228679741614|      Infinity|        2017.1318507063665|          6.600674795023863|         null|   null|    Infinity|                null|1.8604970894699093|4.818410562257704|             null|            null|116.75994381473636|                null|2017.0396918626677|       null|0.010918955497363486|0.010386410695691748|  0.994692909547242|\n",
      "| stddev|        null|              null|1719.5762980004235|           NaN|        1.4067217591560417|          3.438670962224998|         null|   null|         NaN|                null|0.5838700119885731|3.655103672559653|             null|            null| 61.89706130241181|                null| 1.395273414160113|       null|  0.1039218204938707| 0.10138316139358779|0.05298794586937716|\n",
      "|    min|       BLACK|AG MACHINE - OTHER|                 0|      -304745A|                      2014|                          1|          NEW|    ABI|      5085GL|                 CNG|                 0|                0|IMPORTED BUILT-UP|       ARGENTINA|                 0|AGRICULTURAL MACHINE|              2015|1A9SJ022731|                   0|                   0| 0.4477611940298508|\n",
      "|    max|      YELLOW|           UTILITY|             97000|ZZZD1151670065|                      2020|                         12|         USED|ZX AUTO|ZXSSU-SAF771|PLUGIN PETROL HYBRID|                 6|              926|          UNKNOWN|        VIET NAM|               999|             TRACTOR|              2019|ZPBEA1ZLXLL|                   1|                   1|                1.0|\n",
      "+-------+------------+------------------+------------------+--------------+--------------------------+---------------------------+-------------+-------+------------+--------------------+------------------+-----------------+-----------------+----------------+------------------+--------------------+------------------+-----------+--------------------+--------------------+-------------------+\n",
      "\n",
      "+--------------------------+------------+\n",
      "|FIRST_NZ_REGISTRATION_YEAR|sum(EV_flag)|\n",
      "+--------------------------+------------+\n",
      "|                      2015|         110|\n",
      "|                      2016|         337|\n",
      "|                      2017|        1859|\n",
      "|                      2018|        2457|\n",
      "|                      2019|        3581|\n",
      "|                      2020|         821|\n",
      "+--------------------------+------------+\n",
      "\n",
      "839366\n",
      "root\n",
      " |-- BASIC_COLOUR: string (nullable = true)\n",
      " |-- BODY_TYPE: string (nullable = true)\n",
      " |-- CC_RATING: integer (nullable = true)\n",
      " |-- ENGINE_NUMBER: string (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_YEAR: integer (nullable = true)\n",
      " |-- FIRST_NZ_REGISTRATION_MONTH: integer (nullable = true)\n",
      " |-- IMPORT_STATUS: string (nullable = true)\n",
      " |-- MAKE: string (nullable = true)\n",
      " |-- MODEL: string (nullable = true)\n",
      " |-- MOTIVE_POWER: string (nullable = true)\n",
      " |-- NUMBER_OF_AXLES: integer (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: integer (nullable = true)\n",
      " |-- NZ_ASSEMBLED: string (nullable = true)\n",
      " |-- ORIGINAL_COUNTRY: string (nullable = true)\n",
      " |-- POWER_RATING: integer (nullable = true)\n",
      " |-- VEHICLE_TYPE: string (nullable = true)\n",
      " |-- VEHICLE_YEAR: integer (nullable = true)\n",
      " |-- VIN11: string (nullable = true)\n",
      " |-- EV_flag: integer (nullable = false)\n",
      " |-- Promotion: integer (nullable = false)\n",
      " |-- RunningCost: double (nullable = false)\n",
      "\n",
      "+--------------------+-----------------+-----------------+---------------------+----------------------------------+-----------------------------------+---------------------+------------+-------------+--------------------+-----------------------+-----------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+---------------+-----------------+-------------------+\n",
      "|BASIC_COLOUR_missing|BODY_TYPE_missing|CC_RATING_missing|ENGINE_NUMBER_missing|FIRST_NZ_REGISTRATION_YEAR_missing|FIRST_NZ_REGISTRATION_MONTH_missing|IMPORT_STATUS_missing|MAKE_missing|MODEL_missing|MOTIVE_POWER_missing|NUMBER_OF_AXLES_missing|NUMBER_OF_SEATS_missing|NZ_ASSEMBLED_missing|ORIGINAL_COUNTRY_missing|POWER_RATING_missing|VEHICLE_TYPE_missing|VEHICLE_YEAR_missing|       VIN11_missing|EV_flag_missing|Promotion_missing|RunningCost_missing|\n",
      "+--------------------+-----------------+-----------------+---------------------+----------------------------------+-----------------------------------+---------------------+------------+-------------+--------------------+-----------------------+-----------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+---------------+-----------------+-------------------+\n",
      "|                 0.0|              0.0|              0.0| 0.007380570573504275|                               0.0|                                0.0|                  0.0|         0.0|          0.0|                 0.0|                    0.0|                    0.0|                 0.0|                     0.0|                 0.0|                 0.0|                 0.0|0.024352904454076008|            0.0|              0.0|                0.0|\n",
      "+--------------------+-----------------+-----------------+---------------------+----------------------------------+-----------------------------------+---------------------+------------+-------------+--------------------+-----------------------+-----------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+---------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.3 Data exploration \n",
    "# Reverify the transformation\n",
    "\n",
    "df_VehicleAll_EV.head(5)\n",
    "\n",
    "print ('Count of rows: {0}'.format(df_VehicleAll_New.count()))\n",
    "print ('Count of distinct rows: {0}'.format(df_VehicleAll_New.distinct().count()))\n",
    "\n",
    "\n",
    "df_VehicleAll_New = df_VehicleAll_New.dropDuplicates()\n",
    "\n",
    "df_VehicleAll_Sub = df_VehicleAll_New.select (\"BASIC_COLOUR\", \"BODY_TYPE\", \"CC_RATING\",\n",
    "       \"ENGINE_NUMBER\", \"FIRST_NZ_REGISTRATION_YEAR\",\n",
    "       \"FIRST_NZ_REGISTRATION_MONTH\",\n",
    "       \"IMPORT_STATUS\", \"MAKE\",\n",
    "       \"MODEL\", \"MOTIVE_POWER\", \"NUMBER_OF_AXLES\",\n",
    "       \"NUMBER_OF_SEATS\", \"NZ_ASSEMBLED\", \"ORIGINAL_COUNTRY\", \"POWER_RATING\",\n",
    "       \"VEHICLE_TYPE\",\n",
    "       \"VEHICLE_YEAR\", \"VIN11\",\"EV_flag\",\"Promotion\",\"RunningCost\").where(\"FIRST_NZ_REGISTRATION_MONTH < 2020\")\n",
    "\n",
    "df_VehicleAll_Sub.filter(\"EV_flag = 1\").groupBy('EV_flag').mean().show()\n",
    "\n",
    "print(df_VehicleAll_Sub.count())\n",
    "\n",
    "df_VehicleAll_Sub.describe().show()\n",
    "# Data Visualzation\n",
    "\n",
    "df_VehicleAll_Sub.filter(\"EV_flag = 1\").select(\"FIRST_NZ_REGISTRATION_YEAR\",\"EV_flag\").groupBy('FIRST_NZ_REGISTRATION_YEAR').sum('EV_flag').orderBy('FIRST_NZ_REGISTRATION_YEAR').show()\n",
    "\n",
    "print(df_VehicleAll_Sub.count())\n",
    "\n",
    "df_VehicleAll_Sub.printSchema()\n",
    "\n",
    "# Get the missing data validation for each column, and all the columns missing value check pass over 90% \n",
    "df_VehicleAll_Sub.agg(*[(1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing') for c in df_VehicleAll_Sub.columns]).show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective to visualization the sub dataset with columns\n",
    "df_VehicleAll_Sub_EV = df_VehicleAll_Sub.filter(df_VehicleAll_Sub['EV_flag'] == 1).collect()\n",
    "# df_VehicleAll_Sub_EV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the dataset inside relationship \n",
    "To identify which columns would be correlation with the Electric vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|BASIC_COLOUR|sum(EV_flag)|\n",
      "+------------+------------+\n",
      "|       BLACK|        1325|\n",
      "|        BLUE|         899|\n",
      "|       BROWN|          58|\n",
      "|       CREAM|          89|\n",
      "|        GOLD|         129|\n",
      "|       GREEN|         102|\n",
      "|        GREY|         867|\n",
      "|      ORANGE|         226|\n",
      "|      PURPLE|          11|\n",
      "|         RED|         991|\n",
      "|      SILVER|        1178|\n",
      "|       WHITE|        3178|\n",
      "|      YELLOW|         112|\n",
      "+------------+------------+\n",
      "\n",
      "+--------------------------+------------+\n",
      "|FIRST_NZ_REGISTRATION_YEAR|sum(EV_flag)|\n",
      "+--------------------------+------------+\n",
      "|                      2015|         110|\n",
      "|                      2016|         337|\n",
      "|                      2017|        1859|\n",
      "|                      2018|        2457|\n",
      "|                      2019|        3581|\n",
      "|                      2020|         821|\n",
      "+--------------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if the body corlour \n",
    "df_VehicleAll_Sub.filter(\"EV_flag = 1\").select(\"BASIC_COLOUR\",\"EV_flag\").groupBy('BASIC_COLOUR').sum('EV_flag').orderBy('BASIC_COLOUR').show()\n",
    "\n",
    "# Check if the YEAR \n",
    "df_VehicleAll_Sub.filter(\"EV_flag = 1\").select(\"FIRST_NZ_REGISTRATION_YEAR\",\"EV_flag\").groupBy('FIRST_NZ_REGISTRATION_YEAR').sum('EV_flag').orderBy('FIRST_NZ_REGISTRATION_YEAR').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        MOTIVE_POWER| count|\n",
      "+--------------------+------+\n",
      "|                 CNG|    22|\n",
      "|              DIESEL|332152|\n",
      "|DIESEL ELECTRIC H...|    20|\n",
      "|       DIESEL HYBRID|    27|\n",
      "|            ELECTRIC|  9165|\n",
      "|ELECTRIC FUEL CEL...|     2|\n",
      "|ELECTRIC [DIESEL ...|     2|\n",
      "|ELECTRIC [PETROL ...|   338|\n",
      "|                 LPG|   845|\n",
      "|               OTHER|    38|\n",
      "|              PETROL|478853|\n",
      "|PETROL ELECTRIC H...|   206|\n",
      "|       PETROL HYBRID| 14972|\n",
      "|PLUGIN DIESEL HYBRID|    17|\n",
      "|PLUGIN PETROL HYBRID|  2707|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1035, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1035, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-cb22ee471d09>\", line 6, in <module>\n",
      "    df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 318, in show\n",
      "    print(self._jdf.showString(n, 20))\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o617.showString\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o617.showString",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cb22ee471d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_VehicleAll_Sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_VehicleAll_Sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m                                     \u001b[0;34m,\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MOTIVE_POWER\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ELECTRIC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                                     \u001b[0;34m.\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MOTIVE_POWER\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%HYBRID%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                                     \u001b[0;34m.\u001b[0m\u001b[0motherwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MOTIVE_POWER_GRP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_VehicleAll_Sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MOTIVE_POWER_GRP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"VIN11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MOTIVE_POWER_GRP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MOTIVE_POWER_GRP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise Py4JError(\n\u001b[1;32m    326\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o617.showString"
     ]
    }
   ],
   "source": [
    "df_VehicleAll_Sub.select(\"MOTIVE_POWER\",\"VIN11\").groupBy('MOTIVE_POWER').count().orderBy('MOTIVE_POWER').show()\n",
    "#\n",
    "\n",
    "df_VehicleAll_Sub = df_VehicleAll_Sub.select(col(\"*\") \\\n",
    "                                    ,when((col(\"MOTIVE_POWER\") == \"ELECTRIC\"),1) \\\n",
    "                                    .when((col(\"MOTIVE_POWER\").like(\"%HYBRID%\")),1) \\\n",
    "                                    .otherwise(2).alias(\"MOTIVE_POWER_GRP\"))\n",
    "\n",
    "df_VehicleAll_Sub.select(\"MOTIVE_POWER_GRP\",\"VIN11\").groupBy('MOTIVE_POWER_GRP').count().orderBy('MOTIVE_POWER_GRP').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data minging Method Selection\n",
    "#Verify the final dataset \n",
    "Print the pari plot figures to help to identify which type of the function group\n",
    "ML method will be applyed.\n",
    "Based on the \n",
    "VechileAll_Sub = VechileAll[['CC_RATING','NUMBER_OF_SEATS','POWER_RATING','VEHICLE_YEAR','RunningCost','Promotion','EV_Flag']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:36431)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:36431)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6a7f0638b6e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check the coorelation in the pyspark dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_VehicleAll_Sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EV_Flag'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Promotion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, col1, col2, method)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             raise ValueError(\"Currently only the calculation of the Pearson Correlation \" +\n\u001b[1;32m   1424\u001b[0m                              \"coefficient is supported.\")\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    879\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \"\"\"\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    834\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:36431)"
     ]
    }
   ],
   "source": [
    "# Check the coorelation in the pyspark dataframe\n",
    "df_VehicleAll_Sub.corr('EV_Flag','Promotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the linear regression lib to process the dataset\n",
    "import pyspark.mllib.stat as st\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                OneHotEncoder,StringIndexer)\n",
    "spark = SparkSession.builder.appName('logistic_regression_docs').getOrCreate()\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "df_VehicleAll_Sub_DM01 = df_VehicleAll_Sub.select('CC_RATING',\n",
    "       'NUMBER_OF_SEATS', 'POWER_RATING',\n",
    "       'VEHICLE_YEAR','RunningCost','Promotion','EV_Flag')\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['CC_RATING','NUMBER_OF_SEATS','POWER_RATING','VEHICLE_YEAR','RunningCost','Promotion'],\n",
    "    outputCol='EV_Flag')\n",
    "\n",
    "Lr_assembler_output = assembler.transform(df_VehicleAll_Sub_DM01)\n",
    "Lr_assembler_output.printSchema()\n",
    "\n",
    "final_df_VehicleAll = Lr_assembler_output.select(\"EV_Flag\",'RunningCost')\n",
    "final_df_VehicleAll.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(CC_RATING=2199, NUMBER_OF_SEATS=7, POWER_RATING=145, VEHICLE_YEAR=2015, RunningCost=1.0, Promotion=0, EV_Flag=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VehicleAll_Sub_DM01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
